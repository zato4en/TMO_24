{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8427893,
          "sourceType": "datasetVersion",
          "datasetId": 5018553
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'smartphones:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5018553%2F8427893%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240516%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240516T065625Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D38544fd5ecb5501ecc02752307f09dc5c695a5e6af868f4fb5a33c8843846fed6a6ec9e031714d2ea10131c0cf0d8f5611cd7c88e9bf0cd3f528ffdb05c7882b50211c984b1e14192f99392e8aaa392b71fb28590c3e59aa877a29b5e2361295f351e80903911cd764f296b21516d3fadc12ec01d1945a1ab1795deed38894cd54447cbf109408a15f4b12236fc0d8fc6281635add52f8b5c4b69c1a9f9e5d51f8a916a681347c8e46db9fe1cb6f16b13979a71d1a710dc4725b5361976a50efd72d36b80bff3d9550b423d420a5f258451292fa64cdc7442d18f5729a8fc32618c55ab645797cae4e85c914fe86e14e13bf98b09ad6186d85542f70b42d63b6'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Vfwuzxn6MB_L",
        "outputId": "059e40a6-8bd0-4056-a0fb-8933fdc0a4de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading smartphones, 28006 bytes compressed\n",
            "\r[==================================================] 28006 bytes downloaded\n",
            "Downloaded and uncompressed: smartphones\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем необходимые библиотеки\n",
        "!pip install gmdh\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from gmdh import Combi, Multi, Mia, Ria\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('/kaggle/input/smartphones/smartphones.csv')\n",
        "\n",
        "# Просмотр первых строк данных для понимания их структуры\n",
        "print(df.head())\n",
        "\n",
        "# Предварительная обработка данных\n",
        "\n",
        "# Кодирование категориальных признаков\n",
        "label_encoders = {}\n",
        "categorical_columns = ['Brand', 'Model', 'Color', 'Free']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    encoder = LabelEncoder()\n",
        "    df[col] = encoder.fit_transform(df[col])\n",
        "    label_encoders[col] = encoder\n",
        "\n",
        "# Заполнение/удаление пропусков (если есть)\n",
        "df = df.dropna()\n",
        "\n",
        "# Отделяем признаки от целевой переменной\n",
        "X = df[['Brand', 'Model', 'RAM', 'Storage', 'Color', 'Free']]\n",
        "y = df['Final Price']\n",
        "\n",
        "# Стандартизация (нормализация) признаков\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Обучение моделей\n",
        "\n",
        "# 1. Модель стекинга\n",
        "estimators = [('lr', LinearRegression()), ('mlp', MLPRegressor(max_iter=2000))]\n",
        "stacking_regressor = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
        "stacking_regressor.fit(x_train, y_train)\n",
        "stacking_predictions = stacking_regressor.predict(x_test)\n",
        "\n",
        "# 2. Модель многослойного персептрона (MLP)\n",
        "mlp_regressor = MLPRegressor(max_iter=2000, learning_rate_init=0.001, tol=1e-4)\n",
        "mlp_regressor.fit(x_train, y_train)\n",
        "mlp_predictions = mlp_regressor.predict(x_test)\n",
        "\n",
        "# 3. Метод COMBI (линейная модель)\n",
        "combi_model = Combi()\n",
        "combi_model.fit(x_train, y_train)\n",
        "combi_predictions = combi_model.predict(x_test)\n",
        "\n",
        "# 4. Метод MIA (нелинейная модель)\n",
        "mia_model = Mia()\n",
        "mia_model.fit(x_train, y_train)\n",
        "mia_predictions = mia_model.predict(x_test)\n",
        "\n",
        "# Оценка качества моделей\n",
        "metrics = {\n",
        "    'StackingRegressor': mean_absolute_error(y_test, stacking_predictions),\n",
        "    'MLPRegressor': mean_absolute_error(y_test, mlp_predictions),\n",
        "    'COMBI': mean_absolute_error(y_test, combi_predictions),\n",
        "    'MIA': mean_absolute_error(y_test, mia_predictions)\n",
        "}\n",
        "\n",
        "# Вывод метрик\n",
        "for model_name, mae in metrics.items():\n",
        "    print(f'{model_name} MAE: {mae}')\n",
        "\n",
        "# В дополнение, можно также вывести RMSE (среднеквадратичную ошибку)\n",
        "for model_name, preds in zip(metrics.keys(), [stacking_predictions, mlp_predictions, combi_predictions, mia_predictions]):\n",
        "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
        "    print(f'{model_name} RMSE: {rmse}')\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-16T06:52:29.060878Z",
          "iopub.execute_input": "2024-05-16T06:52:29.061319Z",
          "iopub.status.idle": "2024-05-16T06:54:58.740551Z",
          "shell.execute_reply.started": "2024-05-16T06:52:29.06128Z",
          "shell.execute_reply": "2024-05-16T06:54:58.738415Z"
        },
        "trusted": true,
        "id": "R2lGOC2SMB_P",
        "outputId": "0b4e14d1-6e77-4397-8c12-8d6e1b59573b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gmdh in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: docstring-inheritance in /usr/local/lib/python3.10/dist-packages (from gmdh) (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gmdh) (1.25.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     Smartphone     Brand           Model  \\\n",
            "0            Realme C55 8/256GB Sunshower Libre    Realme             C55   \n",
            "1      Samsung Galaxy M23 5G 4/128GB Azul Libre   Samsung      Galaxy M23   \n",
            "2  Motorola Moto G13 4/128GB Azul Lavanda Libre  Motorola        Moto G13   \n",
            "3      Xiaomi Redmi Note 11S 6/128GB Gris Libre    Xiaomi  Redmi Note 11S   \n",
            "4       Nothing Phone (2) 12/512GB Blanco Libre   Nothing       Phone (2)   \n",
            "\n",
            "    RAM  Storage   Color Free  Final Price  \n",
            "0   8.0    256.0  Yellow  Yes       231.60  \n",
            "1   4.0    128.0    Blue  Yes       279.00  \n",
            "2   4.0    128.0    Blue  Yes       179.01  \n",
            "3   6.0    128.0    Gray  Yes       279.99  \n",
            "4  12.0    512.0   White  Yes       799.00  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StackingRegressor MAE: 116.84958678655637\n",
            "MLPRegressor MAE: 115.67861153835231\n",
            "COMBI MAE: 115.82834729028309\n",
            "MIA MAE: 4.433690975720055e+160\n",
            "StackingRegressor RMSE: 171.277668690201\n",
            "MLPRegressor RMSE: 168.31891826496238\n",
            "COMBI RMSE: 166.80217892973366\n",
            "MIA RMSE: inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square\n",
            "  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n"
          ]
        }
      ]
    }
  ]
}